{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All needed import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decouple import config\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import needed for the pre-processing\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All model import\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for the logs\n",
    "from utils.mlflow_logs import log_confusion_matrix, log_fn_and_fp, log_f1_score, log_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable\n",
    "RANDOM_STATE = 42\n",
    "SEED = 42\n",
    "URI = config(\"URI\")\n",
    "EXPERIMENT_ID = \"791343131907353119\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the datasets\n",
    "DATA_PATH = \"datasets/ds_salaries.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FUNCTION = {\n",
    "    \"lightGBM with poisson loss 1\" : HistGradientBoostingRegressor(loss=\"poisson\", learning_rate=0.01, tol=1e-7),\n",
    "    \"lightGBM with poisson loss 2\" : HistGradientBoostingRegressor(loss=\"poisson\", learning_rate=0.05, tol=1e-7),\n",
    "    \"lightGBM with poisson loss 3\" : HistGradientBoostingRegressor(loss=\"poisson\", learning_rate=0.1, tol=1e-7),\n",
    "    \"lightGBM with poisson loss 4\" : HistGradientBoostingRegressor(loss=\"poisson\", learning_rate=0.01, tol=1e-5),\n",
    "    \"lightGBM with poisson loss 5\" : HistGradientBoostingRegressor(loss=\"poisson\", learning_rate=0.05, tol=1e-5),\n",
    "    \"lightGBM with poisson loss 6\" : HistGradientBoostingRegressor(loss=\"poisson\", learning_rate=0.1, tol=1e-5),\n",
    "    \"lightGBM with abs loss 1\" : HistGradientBoostingRegressor(loss=\"absolute_error\", learning_rate=0.01, tol=1e-7),\n",
    "    \"lightGBM with abs loss 2\" : HistGradientBoostingRegressor(loss=\"absolute_error\", learning_rate=0.05, tol=1e-7),\n",
    "    \"lightGBM with abs loss 3\" : HistGradientBoostingRegressor(loss=\"absolute_error\", learning_rate=0.1, tol=1e-7),\n",
    "    \"lightGBM with abs loss 4\" : HistGradientBoostingRegressor(loss=\"absolute_error\", learning_rate=0.01, tol=1e-5),\n",
    "    \"lightGBM with abs loss 5\" : HistGradientBoostingRegressor(loss=\"absolute_error\", learning_rate=0.05, tol=1e-5),\n",
    "    \"lightGBM with abs loss 6\" : HistGradientBoostingRegressor(loss=\"absolute_error\", learning_rate=0.1, tol=1e-5),\n",
    "    \"multi layer perceptron 1\" : MLPRegressor(hidden_layer_sizes=100, activation=\"identity\"),\n",
    "    \"multi layer perceptron 2\" : MLPRegressor(hidden_layer_sizes=100, activation=\"logistic\"),\n",
    "    \"multi layer perceptron 3\" : MLPRegressor(hidden_layer_sizes=100, activation=\"tanh\"),\n",
    "    \"multi layer perceptron 4\" : MLPRegressor(hidden_layer_sizes=100, activation=\"relu\"),\n",
    "    \"multi layer perceptron 5\" : MLPRegressor(hidden_layer_sizes=150, activation=\"identity\"),\n",
    "    \"multi layer perceptron 6\" : MLPRegressor(hidden_layer_sizes=150, activation=\"logistic\"),\n",
    "    \"multi layer perceptron 7\" : MLPRegressor(hidden_layer_sizes=150, activation=\"tanh\"),\n",
    "    \"multi layer perceptron 8\" : MLPRegressor(hidden_layer_sizes=150, activation=\"relu\"),\n",
    "    \"Adaboost 1\" : AdaBoostRegressor(n_estimators=50, loss=\"linear\"),\n",
    "    \"Adaboost 2\" : AdaBoostRegressor(n_estimators=50, loss=\"square\"),\n",
    "    \"Adaboost 3\" : AdaBoostRegressor(n_estimators=50, loss=\"exponential\"),\n",
    "    \"Adaboost 4\" : AdaBoostRegressor(n_estimators=100, loss=\"linear\"),\n",
    "    \"Adaboost 5\" : AdaBoostRegressor(n_estimators=100, loss=\"square\"),\n",
    "    \"Adaboost 6\" : AdaBoostRegressor(n_estimators=100, loss=\"exponential\"),\n",
    "    \"Ridge 1\" : Ridge(alpha=0.25),\n",
    "    \"Ridge 2\" : Ridge(alpha=0.5),\n",
    "    \"Ridge 3\" : Ridge(alpha=1),\n",
    "    \"Ridge 4\" : Ridge(alpha=1.5),\n",
    "    \"Ridge 5\" : Ridge(alpha=2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get and pre-process the datas\n",
    "def get_data(frac: float = 1.0) -> Tuple:\n",
    "    \"\"\"Function used for the weather dataset\"\"\"\n",
    "\n",
    "    data = pd.read_csv(DATA_PATH).sample(frac=frac, random_state=RANDOM_STATE)\n",
    "    target_column = \"salary_in_usd\"\n",
    "    data = data.drop([\"salary_currency\", \"salary\"], axis=1)\n",
    "    for column in [\"experience_level\", \"employment_type\", \"job_title\", \"employee_residence\", \"company_location\", \"company_size\"]:\n",
    "        data[column] = LabelEncoder().fit_transform(data[column])\n",
    "    data = data.dropna(axis=0)\n",
    "\n",
    "    iforest = IsolationForest(contamination=0.1, random_state=RANDOM_STATE)\n",
    "    outliers = iforest.fit_predict(data)\n",
    "    clean_data = data[(outliers != -1)]\n",
    "\n",
    "    # we normalize\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    clean_array = min_max_scaler.fit_transform(clean_data)\n",
    "    clean_data = pd.DataFrame(clean_array, columns=clean_data.keys())\n",
    "\n",
    "    data_values = clean_data.drop([target_column], axis=1)\n",
    "    data_target = clean_data[target_column]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data_values, data_target, test_size=0.3, random_state=RANDOM_STATE\n",
    "    )\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_params(X_train: np.ndarray, X_test: np.ndarray, model_name: str) -> None:\n",
    "    mlflow.log_param(\"nb_features\", X_train.shape[1])\n",
    "    mlflow.log_param(\"nb_samples_train\", X_train.shape[0])\n",
    "    mlflow.log_param(\"nb_samples_test\", X_test.shape[0])\n",
    "    mlflow.log_param(\"model_name\", model_name)\n",
    "    mlflow.log_param(\"model_class\", type(MODEL_FUNCTION[model_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    mlflow.set_tracking_uri(URI)\n",
    "    mlflow.sklearn.autolog()\n",
    "    frac = 1\n",
    "    print(\"data loading\")\n",
    "    (X_train, Y_train), (X_test, Y_test) = get_data(frac)\n",
    "    for model_name in MODEL_FUNCTION:\n",
    "        run_name = f\"Run of {model_name}\"\n",
    "        with mlflow.start_run(run_name=run_name, experiment_id=EXPERIMENT_ID):\n",
    "            model = MODEL_FUNCTION[model_name]\n",
    "            model.fit(X_train, Y_train)\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "            log_params(X_train, X_test, model_name)  # this line is optional\n",
    "            model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "            eval_data = X_test\n",
    "            eval_data[\"label\"] = Y_test\n",
    "            mlflow.evaluate(\n",
    "                model=model_uri,\n",
    "                data=eval_data,\n",
    "                targets=\"label\",\n",
    "                model_type=\"regressor\",\n",
    "                evaluators=\"default\",\n",
    "            )\n",
    "            mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/25 14:42:03 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '82ccbf6219f6459099bba8278bb18c78', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "2023/05/25 14:42:03 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2023/05/25 14:42:03 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\hennecarta\\Anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:130: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/05/25 14:42:25 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:42:25 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:42:28 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:42:44 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:42:44 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:42:47 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:43:03 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:43:03 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:43:06 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:43:22 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:43:22 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:43:25 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:43:41 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:43:41 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:43:44 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:44:00 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:44:00 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:44:04 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:44:20 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:44:20 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:44:23 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:44:39 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:44:39 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:44:43 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:44:59 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:44:59 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:45:03 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:45:20 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:45:20 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:45:23 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:45:41 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:45:41 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:45:45 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:46:00 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:46:00 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:46:04 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'TreeEnsemble' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:46:18 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:46:18 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: MLPRegressor(activation='identity', hidden_layer_sizes=100)\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:46:31 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:46:31 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: MLPRegressor(activation='logistic', hidden_layer_sizes=100)\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:46:44 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:46:44 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: MLPRegressor(activation='tanh', hidden_layer_sizes=100)\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:46:57 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:46:57 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError('The passed model is not callable and cannot be analyzed directly with the given masker! Model: MLPRegressor(hidden_layer_sizes=100)'). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:47:10 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:47:10 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: MLPRegressor(activation='identity', hidden_layer_sizes=150)\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:47:22 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:47:22 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: MLPRegressor(activation='logistic', hidden_layer_sizes=150)\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:47:35 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:47:35 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: MLPRegressor(activation='tanh', hidden_layer_sizes=150)\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:47:50 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:47:50 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError('The passed model is not callable and cannot be analyzed directly with the given masker! Model: MLPRegressor(hidden_layer_sizes=150)'). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:48:02 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:48:02 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError('The passed model is not callable and cannot be analyzed directly with the given masker! Model: AdaBoostRegressor()'). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:48:17 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:48:17 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: AdaBoostRegressor(loss='square')\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:48:31 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:48:31 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: AdaBoostRegressor(loss='exponential')\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:48:43 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:48:43 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError('The passed model is not callable and cannot be analyzed directly with the given masker! Model: AdaBoostRegressor(n_estimators=100)'). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:48:56 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:48:56 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: AdaBoostRegressor(loss='square', n_estimators=100)\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:49:09 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:49:09 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError(\"The passed model is not callable and cannot be analyzed directly with the given masker! Model: AdaBoostRegressor(loss='exponential', n_estimators=100)\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:49:24 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:49:24 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Linear is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:49:24 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'Ridge' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:49:40 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:49:40 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Linear is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:49:40 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'Ridge' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:49:57 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:49:57 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Linear is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:49:57 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'Ridge' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:50:13 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:50:13 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Linear is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:50:13 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'Ridge' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/05/25 14:50:30 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/25 14:50:30 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Linear is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/25 14:50:30 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'Ridge' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n"
     ]
    }
   ],
   "source": [
    "main()  # We launch it all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
